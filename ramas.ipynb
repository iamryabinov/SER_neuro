{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models_one_task import AlexNet, vgg\n",
    "from datasets.ramas import RamasDataset\n",
    "from constants import *\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import skorch\n",
    "from skorch.helper import predefined_split\n",
    "from skorch.dataset import Dataset\n",
    "from skorch.classifier import NeuralNetClassifier\n",
    "import skorch.callbacks as callbacks\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= INITIALIZING DATASET Ramas224Descrete_224_train ===============\n",
      "============================ SUCCESS! =========================\n",
      "============= INITIALIZING DATASET Ramas224Descrete_224_test ===============\n",
      "============================ SUCCESS! =========================\n"
     ]
    }
   ],
   "source": [
    "ramas_224_train = RamasDataset(RAMAS_PATH_TO_WAVS, 'Ramas224Descrete',\n",
    "                 spectrogram_shape=224,\n",
    "                 augmentation=True, padding='repeat', mode='train',  tasks='emotion', type='descrete')\n",
    "ramas_224_test = RamasDataset(RAMAS_PATH_TO_WAVS, 'Ramas224Descrete',\n",
    "                 spectrogram_shape=224,\n",
    "                 augmentation=False, padding='repeat', mode='test',  tasks='emotion', type='descrete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ramas_224_train\n",
    "test_dataset = ramas_224_test\n",
    "filename = 'AlexNet--{}_augmentation-{}.md'.format(train_dataset.name, str(train_dataset.augmentation).lower())\n",
    "best_model_file_path = os.path.join(RESULTS_FOLDER, filename)\n",
    "callback_train_acc = callbacks.EpochScoring(scoring=\"accuracy\", \n",
    "                                            lower_is_better=False, \n",
    "                                            on_train=True, \n",
    "                                            name='train_acc')\n",
    "callback_save_best = callbacks.Checkpoint(monitor='valid_loss_best', \n",
    "                                          f_params=None, \n",
    "                                          f_optimizer=None, \n",
    "                                          f_criterion=None, \n",
    "                                          f_history=None, \n",
    "                                          f_pickle=best_model_file_path,  \n",
    "                                          event_name='event_cp')\n",
    "callback_early_stop = callbacks.EarlyStopping(monitor='valid_loss', patience=30, \n",
    "                                              threshold_mode='rel', lower_is_better=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(num_classes=8)\n",
    "net = skorch.classifier.NeuralNetClassifier(\n",
    "    model, criterion=nn.CrossEntropyLoss, optimizer=torch.optim.Adam,\n",
    "    lr=3e-4, max_epochs=300, batch_size=32, train_split=predefined_split(test_dataset), \n",
    "    device=device, iterator_train__shuffle=True, \n",
    "    callbacks=[\n",
    "        callback_train_acc,\n",
    "        callback_save_best,\n",
    "        callback_early_stop\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.2073\u001b[0m        \u001b[32m1.9601\u001b[0m       \u001b[35m0.2264\u001b[0m        \u001b[31m1.9107\u001b[0m     +  46.6378\n",
      "      2       \u001b[36m0.2225\u001b[0m        \u001b[32m1.8998\u001b[0m       \u001b[35m0.2869\u001b[0m        \u001b[31m1.7789\u001b[0m     +  46.1199\n",
      "      3       \u001b[36m0.2647\u001b[0m        \u001b[32m1.8206\u001b[0m       0.2623        1.8543        46.0725\n",
      "      4       \u001b[36m0.2673\u001b[0m        \u001b[32m1.7855\u001b[0m       \u001b[35m0.2992\u001b[0m        \u001b[31m1.7316\u001b[0m     +  46.0463\n",
      "      5       \u001b[36m0.2855\u001b[0m        \u001b[32m1.7609\u001b[0m       \u001b[35m0.3012\u001b[0m        \u001b[31m1.7265\u001b[0m     +  46.1071\n",
      "      6       \u001b[36m0.2924\u001b[0m        \u001b[32m1.7486\u001b[0m       \u001b[35m0.3053\u001b[0m        \u001b[31m1.7133\u001b[0m     +  46.1171\n",
      "      7       0.2916        \u001b[32m1.7321\u001b[0m       \u001b[35m0.3094\u001b[0m        \u001b[31m1.6991\u001b[0m     +  46.0627\n",
      "      8       \u001b[36m0.3006\u001b[0m        \u001b[32m1.7136\u001b[0m       0.3012        \u001b[31m1.6932\u001b[0m     +  46.0935\n",
      "      9       \u001b[36m0.3057\u001b[0m        1.7159       \u001b[35m0.3197\u001b[0m        \u001b[31m1.6835\u001b[0m     +  46.0566\n",
      "     10       \u001b[36m0.3096\u001b[0m        \u001b[32m1.6948\u001b[0m       \u001b[35m0.3238\u001b[0m        1.6952        46.0964\n",
      "     11       0.3055        \u001b[32m1.6936\u001b[0m       0.2869        1.7072        46.0293\n",
      "     12       \u001b[36m0.3127\u001b[0m        1.7069       0.3176        \u001b[31m1.6722\u001b[0m     +  46.1451\n",
      "     13       \u001b[36m0.3147\u001b[0m        \u001b[32m1.6844\u001b[0m       \u001b[35m0.3381\u001b[0m        \u001b[31m1.6562\u001b[0m     +  46.2036\n",
      "     14       \u001b[36m0.3265\u001b[0m        \u001b[32m1.6667\u001b[0m       0.3135        1.6616        46.3170\n",
      "     15       0.3201        1.6690       \u001b[35m0.3432\u001b[0m        \u001b[31m1.6428\u001b[0m     +  47.2820\n",
      "     16       \u001b[36m0.3365\u001b[0m        \u001b[32m1.6550\u001b[0m       0.3197        1.6555        46.2031\n",
      "     17       \u001b[36m0.3444\u001b[0m        \u001b[32m1.6428\u001b[0m       0.3371        1.6560        47.9756\n",
      "     18       \u001b[36m0.3508\u001b[0m        1.6481       \u001b[35m0.3535\u001b[0m        1.6496        46.5605\n",
      "     19       0.3506        \u001b[32m1.6375\u001b[0m       \u001b[35m0.3555\u001b[0m        1.6460        46.3218\n",
      "     20       \u001b[36m0.3578\u001b[0m        \u001b[32m1.6323\u001b[0m       0.3340        \u001b[31m1.6424\u001b[0m     +  46.3105\n",
      "     21       \u001b[36m0.3626\u001b[0m        \u001b[32m1.6113\u001b[0m       0.3484        \u001b[31m1.6420\u001b[0m     +  46.3165\n",
      "     22       \u001b[36m0.3662\u001b[0m        \u001b[32m1.6031\u001b[0m       0.3412        \u001b[31m1.6402\u001b[0m     +  47.1592\n",
      "     23       \u001b[36m0.3872\u001b[0m        \u001b[32m1.5771\u001b[0m       \u001b[35m0.3607\u001b[0m        \u001b[31m1.6379\u001b[0m     +  46.1561\n",
      "     24       0.3819        1.5782       0.3443        1.6496        46.0864\n",
      "     25       \u001b[36m0.3913\u001b[0m        \u001b[32m1.5728\u001b[0m       \u001b[35m0.3863\u001b[0m        \u001b[31m1.6109\u001b[0m     +  45.8253\n",
      "     26       \u001b[36m0.4006\u001b[0m        \u001b[32m1.5537\u001b[0m       0.3627        1.6229        46.1617\n",
      "     27       \u001b[36m0.4044\u001b[0m        \u001b[32m1.5328\u001b[0m       \u001b[35m0.3873\u001b[0m        1.6136        46.2380\n",
      "     28       \u001b[36m0.4083\u001b[0m        \u001b[32m1.5194\u001b[0m       \u001b[35m0.3883\u001b[0m        \u001b[31m1.6043\u001b[0m     +  46.2257\n",
      "     29       \u001b[36m0.4249\u001b[0m        \u001b[32m1.5190\u001b[0m       \u001b[35m0.3893\u001b[0m        1.6183        46.0951\n",
      "     30       \u001b[36m0.4264\u001b[0m        \u001b[32m1.4959\u001b[0m       \u001b[35m0.3945\u001b[0m        \u001b[31m1.6021\u001b[0m     +  46.3011\n",
      "     31       \u001b[36m0.4390\u001b[0m        \u001b[32m1.4865\u001b[0m       0.3842        \u001b[31m1.5899\u001b[0m     +  46.2426\n",
      "     32       \u001b[36m0.4416\u001b[0m        \u001b[32m1.4770\u001b[0m       0.3934        \u001b[31m1.5875\u001b[0m     +  46.0926\n",
      "     33       \u001b[36m0.4536\u001b[0m        \u001b[32m1.4493\u001b[0m       0.3914        \u001b[31m1.5644\u001b[0m     +  46.1605\n",
      "     34       \u001b[36m0.4667\u001b[0m        \u001b[32m1.4250\u001b[0m       \u001b[35m0.4109\u001b[0m        1.5877        46.1513\n",
      "     35       \u001b[36m0.4728\u001b[0m        \u001b[32m1.4193\u001b[0m       0.3965        1.6145        46.1586\n",
      "     36       \u001b[36m0.4736\u001b[0m        \u001b[32m1.3866\u001b[0m       \u001b[35m0.4180\u001b[0m        1.6249        46.1452\n",
      "     37       \u001b[36m0.4787\u001b[0m        \u001b[32m1.3729\u001b[0m       0.4160        \u001b[31m1.5618\u001b[0m     +  46.2289\n",
      "     38       \u001b[36m0.4969\u001b[0m        \u001b[32m1.3380\u001b[0m       \u001b[35m0.4334\u001b[0m        1.6023        46.1316\n",
      "     39       \u001b[36m0.5028\u001b[0m        \u001b[32m1.3252\u001b[0m       0.4262        1.5886        46.1875\n",
      "     40       \u001b[36m0.5179\u001b[0m        \u001b[32m1.2975\u001b[0m       0.4273        1.6207        46.0928\n",
      "     41       \u001b[36m0.5182\u001b[0m        \u001b[32m1.2787\u001b[0m       0.4170        1.6664        46.0612\n",
      "     42       \u001b[36m0.5415\u001b[0m        \u001b[32m1.2302\u001b[0m       0.4211        1.7445        46.1318\n",
      "     43       \u001b[36m0.5451\u001b[0m        \u001b[32m1.2284\u001b[0m       0.4160        1.6328        46.1792\n",
      "     44       \u001b[36m0.5730\u001b[0m        \u001b[32m1.1935\u001b[0m       0.4232        1.6450        45.9860\n",
      "     45       0.5605        1.1986       0.4170        1.6750        46.0181\n",
      "     46       \u001b[36m0.5828\u001b[0m        \u001b[32m1.1464\u001b[0m       0.4334        1.7433        46.0507\n",
      "     47       \u001b[36m0.6040\u001b[0m        \u001b[32m1.1090\u001b[0m       0.4232        1.8501        46.1645\n",
      "     48       \u001b[36m0.6087\u001b[0m        \u001b[32m1.0938\u001b[0m       \u001b[35m0.4365\u001b[0m        1.7342        46.0370\n",
      "     49       \u001b[36m0.6253\u001b[0m        \u001b[32m1.0381\u001b[0m       0.4232        1.7190        46.1535\n",
      "     50       \u001b[36m0.6461\u001b[0m        \u001b[32m1.0040\u001b[0m       0.4129        1.8501        46.1383\n",
      "     51       \u001b[36m0.6530\u001b[0m        \u001b[32m0.9821\u001b[0m       0.4252        1.8768        46.1492\n",
      "     52       \u001b[36m0.6602\u001b[0m        \u001b[32m0.9492\u001b[0m       0.4129        1.9188        46.0664\n",
      "     53       \u001b[36m0.6789\u001b[0m        \u001b[32m0.8907\u001b[0m       0.4180        1.8290        46.2647\n",
      "     54       \u001b[36m0.6930\u001b[0m        \u001b[32m0.8661\u001b[0m       0.4170        1.8850        46.1108\n",
      "     55       \u001b[36m0.7025\u001b[0m        \u001b[32m0.8512\u001b[0m       0.4293        1.8806        46.1219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(5, 5))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=6400, out_features=2048, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (4): Dropout(p=0.75, inplace=False)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Linear(in_features=512, out_features=8, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_dataset, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ramas_224_train\n",
    "test_dataset = ramas_224_test\n",
    "filename = 'VGGNet--{}_augmentation-{}.md'.format(train_dataset.name, str(train_dataset.augmentation).lower())\n",
    "best_model_file_path = os.path.join(RESULTS_FOLDER, filename)\n",
    "callback_train_acc = callbacks.EpochScoring(scoring=\"accuracy\", \n",
    "                                            lower_is_better=False, \n",
    "                                            on_train=True, \n",
    "                                            name='train_acc')\n",
    "callback_save_best = callbacks.Checkpoint(monitor='valid_loss_best', \n",
    "                                          f_params=None, \n",
    "                                          f_optimizer=None, \n",
    "                                          f_criterion=None, \n",
    "                                          f_history=None, \n",
    "                                          f_pickle=best_model_file_path,  \n",
    "                                          event_name='event_cp')\n",
    "callback_early_stop = callbacks.EarlyStopping(monitor='valid_loss', patience=30, \n",
    "                                              threshold_mode='rel', lower_is_better=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg(type=11, bn=True, num_classes=8)\n",
    "net = skorch.classifier.NeuralNetClassifier(\n",
    "    model, criterion=nn.CrossEntropyLoss, optimizer=torch.optim.Adam,\n",
    "    lr=3e-4, max_epochs=300, batch_size=32, train_split=predefined_split(test_dataset), \n",
    "    device=device, iterator_train__shuffle=True, \n",
    "    callbacks=[\n",
    "        callback_train_acc,\n",
    "        callback_save_best,\n",
    "        callback_early_stop\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.2365\u001b[0m        \u001b[32m1.9116\u001b[0m       \u001b[35m0.1742\u001b[0m        \u001b[31m3.1456\u001b[0m     +  67.4569\n",
      "      2       \u001b[36m0.2704\u001b[0m        \u001b[32m1.7873\u001b[0m       \u001b[35m0.3166\u001b[0m        \u001b[31m1.7154\u001b[0m     +  67.3093\n",
      "      3       \u001b[36m0.2940\u001b[0m        \u001b[32m1.7394\u001b[0m       0.2859        \u001b[31m1.6974\u001b[0m     +  67.3468\n",
      "      4       \u001b[36m0.3091\u001b[0m        \u001b[32m1.7186\u001b[0m       0.2213        2.3580        67.5020\n",
      "      5       \u001b[36m0.3209\u001b[0m        \u001b[32m1.7093\u001b[0m       0.2982        \u001b[31m1.6944\u001b[0m     +  67.5118\n",
      "      6       \u001b[36m0.3278\u001b[0m        \u001b[32m1.6698\u001b[0m       0.2736        2.4418        67.2240\n",
      "      7       \u001b[36m0.3547\u001b[0m        \u001b[32m1.6653\u001b[0m       \u001b[35m0.3463\u001b[0m        \u001b[31m1.6413\u001b[0m     +  67.3927\n",
      "      8       \u001b[36m0.3598\u001b[0m        \u001b[32m1.6426\u001b[0m       0.3443        1.6632        67.3277\n",
      "      9       \u001b[36m0.3865\u001b[0m        \u001b[32m1.6186\u001b[0m       \u001b[35m0.3811\u001b[0m        \u001b[31m1.6149\u001b[0m     +  67.1798\n",
      "     10       \u001b[36m0.3975\u001b[0m        \u001b[32m1.5942\u001b[0m       0.3166        1.9065        67.3908\n",
      "     11       \u001b[36m0.4044\u001b[0m        \u001b[32m1.5757\u001b[0m       \u001b[35m0.3822\u001b[0m        1.7001        67.1412\n",
      "     12       \u001b[36m0.4177\u001b[0m        \u001b[32m1.5478\u001b[0m       0.3197        1.9166        67.6629\n",
      "     13       \u001b[36m0.4295\u001b[0m        \u001b[32m1.5132\u001b[0m       \u001b[35m0.4139\u001b[0m        \u001b[31m1.5567\u001b[0m     +  67.5292\n",
      "     14       \u001b[36m0.4400\u001b[0m        \u001b[32m1.4995\u001b[0m       0.3934        1.5592        67.4332\n",
      "     15       \u001b[36m0.4554\u001b[0m        \u001b[32m1.4857\u001b[0m       0.3801        1.7411        67.3082\n",
      "     16       \u001b[36m0.4680\u001b[0m        \u001b[32m1.4408\u001b[0m       \u001b[35m0.4436\u001b[0m        \u001b[31m1.5382\u001b[0m     +  67.4914\n",
      "     17       0.4659        1.4422       0.3883        1.6183        67.5221\n",
      "     18       \u001b[36m0.4974\u001b[0m        \u001b[32m1.3827\u001b[0m       \u001b[35m0.4590\u001b[0m        \u001b[31m1.4661\u001b[0m     +  67.4962\n",
      "     19       \u001b[36m0.5187\u001b[0m        \u001b[32m1.3317\u001b[0m       0.4395        1.4888        67.2203\n",
      "     20       \u001b[36m0.5246\u001b[0m        \u001b[32m1.3210\u001b[0m       0.4457        1.5114        67.7123\n",
      "     21       \u001b[36m0.5310\u001b[0m        \u001b[32m1.3075\u001b[0m       0.4477        1.4887        67.3147\n",
      "     22       \u001b[36m0.5407\u001b[0m        \u001b[32m1.2673\u001b[0m       \u001b[35m0.4621\u001b[0m        1.4882        67.3252\n",
      "     23       \u001b[36m0.5602\u001b[0m        \u001b[32m1.2107\u001b[0m       0.4436        1.5589        67.7016\n",
      "     24       \u001b[36m0.5815\u001b[0m        \u001b[32m1.1741\u001b[0m       \u001b[35m0.4959\u001b[0m        1.5036        67.5873\n",
      "     25       \u001b[36m0.5823\u001b[0m        \u001b[32m1.1504\u001b[0m       0.4775        \u001b[31m1.4514\u001b[0m     +  67.2344\n",
      "     26       \u001b[36m0.6081\u001b[0m        \u001b[32m1.0688\u001b[0m       0.4508        1.7072        67.3240\n",
      "     27       \u001b[36m0.6240\u001b[0m        \u001b[32m1.0345\u001b[0m       0.4775        1.6588        67.0308\n",
      "     28       \u001b[36m0.6381\u001b[0m        \u001b[32m1.0050\u001b[0m       0.4816        1.6103        67.3748\n",
      "     29       \u001b[36m0.6489\u001b[0m        \u001b[32m0.9771\u001b[0m       0.4918        1.5871        67.0829\n",
      "     30       \u001b[36m0.6758\u001b[0m        \u001b[32m0.9235\u001b[0m       \u001b[35m0.5164\u001b[0m        1.4758        67.2612\n",
      "     31       \u001b[36m0.6925\u001b[0m        \u001b[32m0.8507\u001b[0m       0.4641        1.6333        67.7178\n",
      "     32       \u001b[36m0.7117\u001b[0m        \u001b[32m0.7933\u001b[0m       0.5041        1.7357        67.4125\n",
      "     33       \u001b[36m0.7209\u001b[0m        \u001b[32m0.7817\u001b[0m       0.4816        1.8131        67.3969\n",
      "     34       \u001b[36m0.7232\u001b[0m        \u001b[32m0.7741\u001b[0m       0.4918        1.8536        67.2959\n",
      "     35       \u001b[36m0.7673\u001b[0m        \u001b[32m0.6706\u001b[0m       0.4662        1.7615        67.5811\n",
      "     36       \u001b[36m0.7824\u001b[0m        \u001b[32m0.6255\u001b[0m       0.4570        1.9135        67.2649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU(inplace=True)\n",
       "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Linear(in_features=512, out_features=8, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_dataset, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= INITIALIZING DATASET Ramas224Binary_224_train ===============\n",
      "============================ SUCCESS! =========================\n",
      "============= INITIALIZING DATASET Ramas224Binary_224_test ===============\n",
      "============================ SUCCESS! =========================\n"
     ]
    }
   ],
   "source": [
    "ramas_224_train = RamasDataset(RAMAS_PATH_TO_WAVS, 'Ramas224Binary',\n",
    "                 spectrogram_shape=224,\n",
    "                 augmentation=True, padding='repeat', mode='train',  tasks='emotion', type='binary')\n",
    "ramas_224_test = RamasDataset(RAMAS_PATH_TO_WAVS, 'Ramas224Binary',\n",
    "                 spectrogram_shape=224,\n",
    "                 augmentation=False, padding='repeat', mode='test',  tasks='emotion', type='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ramas_224_train\n",
    "test_dataset = ramas_224_test\n",
    "filename = 'AlexNet--{}_augmentation-{}.md'.format(train_dataset.name, str(train_dataset.augmentation).lower())\n",
    "best_model_file_path = os.path.join(RESULTS_FOLDER, filename)\n",
    "callback_train_acc = callbacks.EpochScoring(scoring=\"accuracy\", \n",
    "                                            lower_is_better=False, \n",
    "                                            on_train=True, \n",
    "                                            name='train_acc')\n",
    "callback_save_best = callbacks.Checkpoint(monitor='valid_loss_best', \n",
    "                                          f_params=None, \n",
    "                                          f_optimizer=None, \n",
    "                                          f_criterion=None, \n",
    "                                          f_history=None, \n",
    "                                          f_pickle=best_model_file_path,  \n",
    "                                          event_name='event_cp')\n",
    "callback_early_stop = callbacks.EarlyStopping(monitor='valid_loss', patience=20, \n",
    "                                              threshold_mode='rel', lower_is_better=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlexNet(num_classes=2)\n",
    "net = skorch.classifier.NeuralNetClassifier(\n",
    "    model, criterion=nn.CrossEntropyLoss, optimizer=torch.optim.Adam,\n",
    "    lr=1e-5, max_epochs=300, batch_size=32, train_split=predefined_split(test_dataset), \n",
    "    device=device, iterator_train__shuffle=True, \n",
    "    callbacks=[\n",
    "        callback_train_acc,\n",
    "        callback_save_best,\n",
    "#         callback_early_stop\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.7873\u001b[0m        \u001b[32m0.5056\u001b[0m       \u001b[35m0.8299\u001b[0m        \u001b[31m0.4718\u001b[0m     +  46.1976\n",
      "      2       \u001b[36m0.8298\u001b[0m        \u001b[32m0.4650\u001b[0m       0.8299        \u001b[31m0.4591\u001b[0m     +  45.6342\n",
      "      3       0.8298        \u001b[32m0.4555\u001b[0m       0.8299        0.4635        46.3378\n",
      "      4       0.8298        \u001b[32m0.4433\u001b[0m       0.8299        \u001b[31m0.4377\u001b[0m     +  45.6760\n",
      "      5       0.8298        \u001b[32m0.4338\u001b[0m       0.8299        0.4388        45.5918\n",
      "      6       0.8298        \u001b[32m0.4266\u001b[0m       0.8299        \u001b[31m0.4275\u001b[0m     +  45.7920\n",
      "      7       0.8298        \u001b[32m0.4190\u001b[0m       0.8299        \u001b[31m0.4201\u001b[0m     +  45.9176\n",
      "      8       0.8298        \u001b[32m0.4109\u001b[0m       0.8299        \u001b[31m0.4131\u001b[0m     +  45.8273\n",
      "      9       \u001b[36m0.8301\u001b[0m        \u001b[32m0.4058\u001b[0m       0.8299        \u001b[31m0.4110\u001b[0m     +  46.0009\n",
      "     10       \u001b[36m0.8306\u001b[0m        \u001b[32m0.4009\u001b[0m       \u001b[35m0.8320\u001b[0m        \u001b[31m0.4057\u001b[0m     +  45.6033\n",
      "     11       \u001b[36m0.8321\u001b[0m        \u001b[32m0.3938\u001b[0m       \u001b[35m0.8350\u001b[0m        \u001b[31m0.4017\u001b[0m     +  45.8485\n",
      "     12       \u001b[36m0.8337\u001b[0m        \u001b[32m0.3912\u001b[0m       \u001b[35m0.8525\u001b[0m        \u001b[31m0.3971\u001b[0m     +  45.8890\n",
      "     13       \u001b[36m0.8370\u001b[0m        \u001b[32m0.3879\u001b[0m       \u001b[35m0.8545\u001b[0m        0.4003        45.7526\n",
      "     14       \u001b[36m0.8416\u001b[0m        \u001b[32m0.3811\u001b[0m       0.8422        0.4014        45.7680\n",
      "     15       \u001b[36m0.8437\u001b[0m        \u001b[32m0.3791\u001b[0m       0.8391        0.3998        45.6793\n",
      "     16       0.8393        0.3830       \u001b[35m0.8627\u001b[0m        \u001b[31m0.3919\u001b[0m     +  45.6475\n",
      "     17       0.8419        \u001b[32m0.3770\u001b[0m       0.8555        \u001b[31m0.3864\u001b[0m     +  45.7031\n",
      "     18       \u001b[36m0.8460\u001b[0m        \u001b[32m0.3740\u001b[0m       0.8371        0.3998        45.7553\n",
      "     19       \u001b[36m0.8480\u001b[0m        \u001b[32m0.3656\u001b[0m       0.8607        0.3996        46.0934\n",
      "     20       0.8442        0.3712       0.8473        \u001b[31m0.3844\u001b[0m     +  46.4365\n",
      "     21       0.8450        \u001b[32m0.3652\u001b[0m       0.8094        0.4148        46.0393\n",
      "     22       0.8473        \u001b[32m0.3637\u001b[0m       0.8566        \u001b[31m0.3814\u001b[0m     +  46.0423\n",
      "     23       \u001b[36m0.8485\u001b[0m        \u001b[32m0.3582\u001b[0m       0.8525        \u001b[31m0.3759\u001b[0m     +  45.8535\n",
      "     24       \u001b[36m0.8542\u001b[0m        \u001b[32m0.3571\u001b[0m       0.8586        \u001b[31m0.3755\u001b[0m     +  46.1087\n",
      "     25       \u001b[36m0.8544\u001b[0m        \u001b[32m0.3537\u001b[0m       0.8525        0.3768        46.3748\n",
      "     26       \u001b[36m0.8557\u001b[0m        \u001b[32m0.3498\u001b[0m       0.8596        0.3789        45.8663\n",
      "     27       0.8501        0.3521       0.8443        0.3817        45.8490\n",
      "     28       0.8529        \u001b[32m0.3474\u001b[0m       0.8566        0.3757        45.8103\n",
      "     29       \u001b[36m0.8655\u001b[0m        \u001b[32m0.3401\u001b[0m       0.8617        0.3864        45.7039\n",
      "     30       0.8647        \u001b[32m0.3385\u001b[0m       0.8320        0.3929        45.8094\n",
      "     31       0.8647        \u001b[32m0.3287\u001b[0m       0.8494        0.3797        45.8306\n",
      "     32       0.8619        0.3311       0.8504        0.3780        45.6670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=AlexNet(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (7): ReLU(inplace=True)\n",
       "      (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): ReLU(inplace=True)\n",
       "      (10): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(5, 5))\n",
       "    (classifier): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Linear(in_features=6400, out_features=2048, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Linear(in_features=512, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_dataset, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ramas_224_train\n",
    "test_dataset = ramas_224_test\n",
    "filename = 'VGGNet--{}_augmentation-{}.md'.format(train_dataset.name, str(train_dataset.augmentation).lower())\n",
    "best_model_file_path = os.path.join(RESULTS_FOLDER, filename)\n",
    "callback_train_acc = callbacks.EpochScoring(scoring=\"accuracy\", \n",
    "                                            lower_is_better=False, \n",
    "                                            on_train=True, \n",
    "                                            name='train_acc')\n",
    "callback_save_best = callbacks.Checkpoint(monitor='valid_loss_best', \n",
    "                                          f_params=None, \n",
    "                                          f_optimizer=None, \n",
    "                                          f_criterion=None, \n",
    "                                          f_history=None, \n",
    "                                          f_pickle=best_model_file_path,  \n",
    "                                          event_name='event_cp')\n",
    "callback_early_stop = callbacks.EarlyStopping(monitor='valid_loss', patience=20, \n",
    "                                              threshold_mode='rel', lower_is_better=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg(type=11, bn=True, num_classes=2)\n",
    "net = skorch.classifier.NeuralNetClassifier(\n",
    "    model, criterion=nn.CrossEntropyLoss, optimizer=torch.optim.Adam,\n",
    "    lr=1e-5, max_epochs=300, batch_size=32, train_split=predefined_split(test_dataset), \n",
    "    device=device, iterator_train__shuffle=True, \n",
    "    callbacks=[\n",
    "        callback_train_acc,\n",
    "        callback_save_best,\n",
    "#         callback_early_stop\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_acc    train_loss    valid_acc    valid_loss    cp      dur\n",
      "-------  -----------  ------------  -----------  ------------  ----  -------\n",
      "      1       \u001b[36m0.8291\u001b[0m        \u001b[32m0.4510\u001b[0m       \u001b[35m0.8299\u001b[0m        \u001b[31m0.4352\u001b[0m     +  67.4910\n",
      "      2       \u001b[36m0.8296\u001b[0m        \u001b[32m0.4287\u001b[0m       0.8279        \u001b[31m0.4298\u001b[0m     +  67.6558\n",
      "      3       \u001b[36m0.8309\u001b[0m        \u001b[32m0.4207\u001b[0m       0.8299        \u001b[31m0.4125\u001b[0m     +  67.5511\n",
      "      4       \u001b[36m0.8334\u001b[0m        \u001b[32m0.4009\u001b[0m       \u001b[35m0.8443\u001b[0m        0.4138        67.7493\n",
      "      5       \u001b[36m0.8385\u001b[0m        \u001b[32m0.3918\u001b[0m       \u001b[35m0.8453\u001b[0m        \u001b[31m0.4003\u001b[0m     +  67.7085\n",
      "      6       0.8385        \u001b[32m0.3825\u001b[0m       0.8381        0.4027        67.6332\n",
      "      7       \u001b[36m0.8444\u001b[0m        \u001b[32m0.3754\u001b[0m       0.8258        0.4088        67.7724\n",
      "      8       0.8429        \u001b[32m0.3694\u001b[0m       0.8217        0.4211        67.6102\n",
      "      9       \u001b[36m0.8526\u001b[0m        \u001b[32m0.3563\u001b[0m       \u001b[35m0.8596\u001b[0m        \u001b[31m0.3851\u001b[0m     +  67.7306\n",
      "     10       \u001b[36m0.8567\u001b[0m        \u001b[32m0.3489\u001b[0m       0.8443        0.4391        67.7611\n",
      "     11       \u001b[36m0.8590\u001b[0m        0.3490       0.8525        0.3940        67.7689\n",
      "     12       \u001b[36m0.8621\u001b[0m        \u001b[32m0.3365\u001b[0m       0.8596        \u001b[31m0.3848\u001b[0m     +  67.7461\n",
      "     13       \u001b[36m0.8660\u001b[0m        \u001b[32m0.3315\u001b[0m       \u001b[35m0.8658\u001b[0m        \u001b[31m0.3807\u001b[0m     +  67.9548\n",
      "     14       \u001b[36m0.8708\u001b[0m        \u001b[32m0.3232\u001b[0m       0.7900        0.4452        67.7315\n",
      "     15       \u001b[36m0.8754\u001b[0m        \u001b[32m0.3048\u001b[0m       0.8525        0.4448        67.5484\n",
      "     16       0.8744        0.3139       0.6803        0.6525        68.1214\n",
      "     17       \u001b[36m0.8834\u001b[0m        \u001b[32m0.2976\u001b[0m       0.8658        \u001b[31m0.3793\u001b[0m     +  67.6675\n",
      "     18       \u001b[36m0.8849\u001b[0m        \u001b[32m0.2920\u001b[0m       0.8658        0.3922        67.6384\n",
      "     19       \u001b[36m0.8872\u001b[0m        \u001b[32m0.2821\u001b[0m       0.8658        0.3975        67.5684\n",
      "     20       \u001b[36m0.8962\u001b[0m        \u001b[32m0.2633\u001b[0m       0.7766        0.4923        67.5913\n",
      "     21       0.8962        \u001b[32m0.2545\u001b[0m       \u001b[35m0.8740\u001b[0m        0.3817        67.7550\n",
      "     22       \u001b[36m0.8977\u001b[0m        0.2597       0.8709        0.3935        67.5473\n",
      "     23       \u001b[36m0.9072\u001b[0m        \u001b[32m0.2361\u001b[0m       0.7172        0.6037        67.5275\n",
      "     24       0.9052        \u001b[32m0.2352\u001b[0m       0.8361        0.4302        67.5340\n",
      "     25       \u001b[36m0.9136\u001b[0m        \u001b[32m0.2130\u001b[0m       0.8453        0.7059        67.4814\n",
      "     26       \u001b[36m0.9239\u001b[0m        \u001b[32m0.2045\u001b[0m       0.8668        0.5875        67.6556\n",
      "     27       \u001b[36m0.9303\u001b[0m        \u001b[32m0.1946\u001b[0m       0.8402        0.7563        67.6756\n",
      "     28       0.9241        0.1957       0.5410        1.2823        67.5774\n",
      "     29       0.9293        \u001b[32m0.1808\u001b[0m       0.8730        0.4187        67.6932\n",
      "     30       \u001b[36m0.9421\u001b[0m        \u001b[32m0.1604\u001b[0m       0.8596        0.5896        67.6281\n",
      "     31       0.9305        0.1640       0.7971        0.5014        67.8030\n",
      "     32       0.9377        0.1659       \u001b[35m0.8781\u001b[0m        0.5233        67.5991\n",
      "     33       \u001b[36m0.9528\u001b[0m        \u001b[32m0.1327\u001b[0m       0.8535        0.6826        67.7013\n",
      "     34       \u001b[36m0.9557\u001b[0m        \u001b[32m0.1207\u001b[0m       0.8719        0.5481        67.5847\n",
      "     35       \u001b[36m0.9587\u001b[0m        0.1246       0.8381        0.6686        67.5026\n",
      "     36       0.9528        0.1259       0.8330        1.3412        67.9452\n",
      "     37       \u001b[36m0.9659\u001b[0m        \u001b[32m0.1013\u001b[0m       0.8217        0.5412        67.7303\n",
      "     38       0.9631        \u001b[32m0.0976\u001b[0m       0.8094        0.5648        67.5886\n",
      "     39       \u001b[36m0.9690\u001b[0m        \u001b[32m0.0840\u001b[0m       0.8678        0.5736        67.8863\n",
      "     40       0.9557        0.1196       0.8525        0.8221        67.6115\n",
      "     41       \u001b[36m0.9764\u001b[0m        \u001b[32m0.0707\u001b[0m       0.8555        1.1236        67.8251\n",
      "     42       0.9754        \u001b[32m0.0666\u001b[0m       0.8658        0.7807        67.5956\n",
      "     43       \u001b[36m0.9785\u001b[0m        0.0711       0.7592        0.8427        67.7360\n",
      "     44       0.9728        0.0735       0.7121        1.1228        67.5018\n",
      "     45       0.9746        0.0767       0.8658        0.5791        67.6826\n",
      "     46       \u001b[36m0.9851\u001b[0m        \u001b[32m0.0457\u001b[0m       0.8668        0.8138        67.5293\n",
      "     47       0.9790        0.0597       0.8443        0.8614        67.6377\n",
      "     48       0.9792        0.0604       0.7059        1.0318        67.9123\n",
      "     49       0.9844        0.0512       0.7889        0.8070        67.5496\n",
      "     50       \u001b[36m0.9859\u001b[0m        \u001b[32m0.0425\u001b[0m       0.8586        1.3285        67.6463\n",
      "     51       0.9859        0.0465       0.8586        0.8798        67.6492\n",
      "     52       0.9831        0.0486       0.4385        3.2229        67.7882\n",
      "     53       0.9833        0.0491       0.8566        0.7417        67.6407\n",
      "     54       \u001b[36m0.9869\u001b[0m        \u001b[32m0.0405\u001b[0m       0.8504        1.1308        67.5599\n",
      "     55       0.9808        0.0552       0.8227        0.7356        67.4673\n",
      "     56       \u001b[36m0.9874\u001b[0m        \u001b[32m0.0336\u001b[0m       0.8555        0.7892        67.6228\n",
      "     57       0.9821        0.0462       0.8330        0.7080        67.7418\n",
      "     58       \u001b[36m0.9913\u001b[0m        \u001b[32m0.0278\u001b[0m       0.7951        1.0255        67.8036\n",
      "     59       0.9864        0.0439       0.8586        0.7937        67.7615\n",
      "     60       0.9818        0.0552       0.8289        0.7017        67.5920\n",
      "     61       0.9905        0.0301       0.7254        1.1649        67.6481\n",
      "     62       0.9862        0.0382       0.8709        1.0487        67.5746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ReLU(inplace=True)\n",
       "      (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=2048, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Linear(in_features=512, out_features=2, bias=True)\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(train_dataset, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
