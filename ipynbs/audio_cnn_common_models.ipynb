{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sDkzLRrjxnih"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "from torchsummary import summary\n",
    "from torchvision import models\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "import librosa\n",
    "import random\n",
    "\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvjQyiVx2cR8"
   },
   "outputs": [],
   "source": [
    "def get_paths_to_wavs(path_to_dataset):\n",
    "    file_paths_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path_to_dataset):\n",
    "        if len(files) != 0:\n",
    "            file_paths_list += [os.path.join(root, f) for f in files if f.endswith('.wav')]\n",
    "\n",
    "    return file_paths_list\n",
    "\n",
    "def get_paths_to_npys(path_to_dataset):\n",
    "    # get a list with all absolute paths to each file\n",
    "    file_paths_list = []\n",
    "\n",
    "    for root, dirs, files in os.walk(path_to_dataset):\n",
    "        if len(files) != 0:\n",
    "            file_paths_list += [os.path.join(root, f) for f in files if f.endswith('.npy')]\n",
    "            #file_paths_list += [os.path.join(root, f) for f in files if os.path.isdir(os.path.join(root, f))]\n",
    "\n",
    "    return file_paths_list\n",
    "\n",
    "class numpy_ravdess_dataset(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Due to librosa reads wav-files very slow it is more preferable to read the\n",
    "    numpy representations of the original wavs\n",
    "    '''\n",
    "\n",
    "    emotions_dict = {\n",
    "        0: 'neutral',\n",
    "        1: 'calm',\n",
    "        2: 'happy',\n",
    "        3: 'sad',\n",
    "        4: 'angry',\n",
    "        5: 'fearful',\n",
    "        6: 'disgust',\n",
    "        7: 'surprised'\n",
    "        }\n",
    "\n",
    "    def __init__(self, paths_to_wavs_list, spectrogram_shape, mode):\n",
    "        super(numpy_ravdess_dataset, self).__init__()\n",
    "\n",
    "        self.paths_to_wavs_list = paths_to_wavs_list\n",
    "\n",
    "        self.mfcc_rows = spectrogram_shape[0]\n",
    "        self.mfcc_cols = spectrogram_shape[1]\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths_to_wavs_list)\n",
    "    '''\n",
    "    def read_audio(self, path_to_wav):\n",
    "        return np.load(path_to_wav, allow_pickle=True)\n",
    "    '''\n",
    "    def read_audio(self, path_to_wav):\n",
    "        sr, wav = wavfile.read(path_to_wav)\n",
    "        wav = (wav / 32768).astype(np.float32)\n",
    "        return wav, sr\n",
    "\n",
    "    def get_class_label(self, path_to_file):\n",
    "        # Parse the filename, which has the following pattern:\n",
    "        # modality-vocal_channel-emotion-intensity-statement-repetition-actor.wav\n",
    "        # e.g., '02-01-06-01-02-01-12.wav'\n",
    "        file_name = os.path.split(path_to_file)[1]\n",
    "        file_name = file_name[:-4]\n",
    "        class_label = int(file_name.split('-')[2]) - 1 # 2 is a number of emotion code\n",
    "        return class_label\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path_to_wav = self.paths_to_wavs_list[idx]\n",
    "        # debug\n",
    "        #print(path_to_wav)\n",
    "\n",
    "        # read the wav file\n",
    "        wav, sr = self.read_audio(path_to_wav)       \n",
    "\n",
    "        # augmentation\n",
    "        \n",
    "        if self.mode == 'TRAIN':\n",
    "            # add noise\n",
    "            if np.random.randint(0, 2) == 1:\n",
    "                sigma = np.random.uniform(0.0009, 0.0051)\n",
    "                noise = sigma * np.random.randn(len(wav))\n",
    "                wav += noise\n",
    "            # stretch wav\n",
    "            if np.random.randint(0, 2) == 1:\n",
    "                factor = np.random.uniform(0.5, 1.2)\n",
    "                wav = librosa.effects.time_stretch(wav, 2)\n",
    "            # change pitch\n",
    "            if np.random.randint(0, 2) == 1:\n",
    "                factor = np.random.uniform(-1.5, 1.1)\n",
    "                wav = librosa.effects.pitch_shift(wav, sr=sr, n_steps=factor)\n",
    "    \n",
    "        # get mfcc coefficients\n",
    "        #mfccs = librosa.feature.mfcc(wav, sr=sr, n_mfcc=self.mfcc_rows, n_mels=self.mfcc_rows).astype(np.float32)\n",
    "        '''\n",
    "        if self.mode == 'TRAIN':\n",
    "            # augment by choosing n_fft\n",
    "            n_fft_list = [i for i in range(1024, 2049, 32)]\n",
    "            idx = np.random.randint(len(n_fft_list))\n",
    "            n_fft = n_fft_list[idx]\n",
    "        else:\n",
    "            n_fft = 2048\n",
    "\n",
    "        '''\n",
    "        '''\n",
    "        n_fft = 2048\n",
    "        mfccs = librosa.feature.melspectrogram(wav, sr=sr, n_mels=self.mfcc_rows, n_fft=n_fft, hop_length=128).astype(np.float32)\n",
    "\n",
    "        '''\n",
    "        mfccs = librosa.core.stft(wav, n_fft=512)#.astype(np.float32)\n",
    "        mfccs = np.abs(mfccs)**2\n",
    "        mfccs = np.log(mfccs + 0.1)\n",
    "        mfccs = mfccs[:-1]\n",
    "        \n",
    "        #mfccs = (mfccs - mfccs.mean())/np.std(mfccs)\n",
    "\n",
    "        actual_mfcc_cols = mfccs.shape[1]\n",
    "\n",
    "        # prmitive time-shifting augmentation\n",
    "        target_real_diff = actual_mfcc_cols - self.mfcc_cols\n",
    "        if target_real_diff > 0:\n",
    "            \n",
    "            if self.mode == 'TRAIN':\n",
    "                beginning_col = np.random.randint(target_real_diff)\n",
    "            else:\n",
    "                beginning_col = actual_mfcc_cols//2 - self.mfcc_cols//2\n",
    "\n",
    "            mfccs = mfccs[:, beginning_col:beginning_col + self.mfcc_cols]\n",
    "            #mfccs = mfccs[:, beginning_col:beginning_col + self.mfcc_cols]\n",
    "\n",
    "        elif target_real_diff < 0:\n",
    "            zeros = np.zeros((self.mfcc_rows, self.mfcc_cols), dtype=np.float32)\n",
    "            \n",
    "            if self.mode == 'TRAIN':\n",
    "                beginning_col = np.random.randint(self.mfcc_cols-actual_mfcc_cols)\n",
    "            else:\n",
    "            \n",
    "                beginning_col = self.mfcc_cols//2 - actual_mfcc_cols//2\n",
    "            zeros[..., beginning_col:beginning_col+actual_mfcc_cols] = mfccs\n",
    "            #zeros[..., beginning_col:beginning_col+actual_mfcc_cols] = mfccs\n",
    "            mfccs = zeros\n",
    "            #mfccs = np.pad(mfccs, ((0, 0), (0, np.abs(target_real_diff))), constant_values=(0), mode='constant')\n",
    "\n",
    "        # make the data compatible to pytorch 1-channel CNNs format\n",
    "        mfccs = np.expand_dims(mfccs, axis=0)\n",
    "\n",
    "        # normalize spectrogram\n",
    "        mfccs = (mfccs - mfccs.mean())/np.std(mfccs)\n",
    "\n",
    "        # Parse the filename, which has the following pattern:\n",
    "        # modality-vocal_channel-emotion-intensity-statement-repetition-actor.wav\n",
    "        # e.g., '02-01-06-01-02-01-12.wav'\n",
    "        #file_name = os.path.split(path_to_wav)[1]\n",
    "        #file_name = file_name[:-4]\n",
    "        #class_label = int(file_name.split('-')[2]) - 1 # 2 is a number of emotion code\n",
    "        #class_label = np.array(class_label)\n",
    "        class_label = self.get_class_label(path_to_wav)\n",
    "        # !!!!!!!!!\n",
    "        return torch.from_numpy(mfccs), class_label#, path_to_wav\n",
    "\n",
    "class numpy_crema_dataset(numpy_ravdess_dataset):\n",
    "    emotions_dict = {\n",
    "        'ANG': 0,\n",
    "        'DIS': 1,\n",
    "        'FEA': 2,\n",
    "        'SAD': 3,\n",
    "        'HAP': 4,\n",
    "        'NEU': 5\n",
    "    }\n",
    "\n",
    "    label2str = {\n",
    "        0: 'ANG',\n",
    "        1: 'DIS',\n",
    "        2: 'FEA',\n",
    "        3: 'SAD',\n",
    "        4: 'HAP',\n",
    "        5: 'NEU'\n",
    "    }\n",
    "    \n",
    "    def get_class_label(self, path_to_file):\n",
    "        file_name = os.path.split(path_to_file)[1]\n",
    "        file_name = file_name[:-4]\n",
    "        emotion_name = file_name.split('_')[2] # 2 is a number of emotion code\n",
    "        return self.emotions_dict[emotion_name]\n",
    "\n",
    "class numpy_iemocap_dataset(numpy_ravdess_dataset):\n",
    "    '''\n",
    "    emotions_dict = {\n",
    "        'exc': 0,\n",
    "        'sad': 1,\n",
    "        'fru': 2,\n",
    "        'hap': 3,\n",
    "        'neu': 4,\n",
    "        'sur': 5,\n",
    "        'ang': 6,\n",
    "        'fea': 7,\n",
    "        'dis': 8,\n",
    "        #'oth': 9\n",
    "    }\n",
    "    '''\n",
    "    emotions_dict = {\n",
    "        'exc': 0,\n",
    "        'sad': 1,\n",
    "        'fru': 2,\n",
    "        'hap': 3,\n",
    "        'neu': 4,\n",
    "        'ang': 5,\n",
    "    }\n",
    "\n",
    "    def get_class_label(self, path_to_file):\n",
    "        file_name = os.path.split(path_to_file)[1]\n",
    "        file_name = file_name[:-4]\n",
    "        emotion_name = file_name.split('_')[-1] # the last is a position of emotion code\n",
    "        return self.emotions_dict[emotion_name]\n",
    "\n",
    "class crema_gender_dataset(numpy_ravdess_dataset):\n",
    "    emotions_dict = {\n",
    "        'ANG_Male': 0,\n",
    "        'DIS_Male': 1,\n",
    "        'FEA_Male': 2,\n",
    "        'SAD_Male': 3,\n",
    "        'HAP_Male': 4,\n",
    "        'NEU_Male': 5,\n",
    "        'ANG_Female': 6,\n",
    "        'DIS_Female': 7,\n",
    "        'FEA_Female': 8,\n",
    "        'SAD_Female': 9,\n",
    "        'HAP_Female': 10,\n",
    "        'NEU_Female': 11\n",
    "    }\n",
    "\n",
    "    label2str = {\n",
    "        0: 'ANG',\n",
    "        1: 'DIS',\n",
    "        2: 'FEA',\n",
    "        3: 'SAD',\n",
    "        4: 'HAP',\n",
    "        5: 'NEU'\n",
    "    }\n",
    "    def __init__(self, paths_to_wavs_list, spectrogram_shape, mode, gender_df):\n",
    "        super().__init__(paths_to_wavs_list, spectrogram_shape, mode)\n",
    "        self.gender_df = gender_df\n",
    "    \n",
    "    def get_class_label(self, path_to_file):\n",
    "        \n",
    "        file_name = os.path.split(path_to_file)[1]\n",
    "        file_name = file_name[:-4]\n",
    "        name_list = file_name.split('_') # 2 is a number of emotion code\n",
    "        emotion_name = name_list[2]\n",
    "        actor_id = int(name_list[0])\n",
    "\n",
    "        gender = self.gender_df[self.gender_df['ActorID'] == actor_id]['Sex'].values[0]\n",
    "\n",
    "        return self.emotions_dict['{}_{}'.format(emotion_name, gender)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLRqKFlWE6tA"
   },
   "outputs": [],
   "source": [
    "def index_dataset(paths_list):\n",
    "    human_id_dict = {}# OrderedDict()\n",
    "    phrase_dict = {}#OrderedDict()\n",
    "    emotion_dict = {}#OrderedDict()\n",
    "    \n",
    "    for path in paths_list:\n",
    "        file_name = os.path.split(path)[1]\n",
    "        file_name = file_name[:-4]\n",
    "        name_list = file_name.split('_') # 2 is a number of emotion code\n",
    "        human_id = name_list[0]\n",
    "        phrase_id = name_list[1]\n",
    "        emotion_name = name_list[2]\n",
    "        \n",
    "        try:\n",
    "            human_id_dict[human_id] += 1\n",
    "        except KeyError:\n",
    "            human_id_dict[human_id] = 1\n",
    "\n",
    "        try:\n",
    "            phrase_dict[phrase_id] += 1\n",
    "        except KeyError:\n",
    "            phrase_dict[phrase_id] = 1\n",
    "\n",
    "        try:\n",
    "            emotion_dict[emotion_name] += 1\n",
    "        except KeyError:\n",
    "            emotion_dict[emotion_name] = 1\n",
    "\n",
    "    for key in emotion_dict:\n",
    "        emotion_dict[key] /= len(paths_list)\n",
    "\n",
    "    for key in phrase_dict:\n",
    "        phrase_dict[key] /= len(paths_list)\n",
    "\n",
    "    for key in human_id_dict:\n",
    "        human_id_dict[key] /= len(paths_list)\n",
    "\n",
    "    return human_id_dict, phrase_dict, emotion_dict\n",
    "\n",
    "def validate(model, criterion, testloader, device):\n",
    "\n",
    "    dataset_size = len(testloader.dataset)  \n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for i, (data, target) in enumerate(testloader):\n",
    "        t0 = time.time()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # run forward step\n",
    "            predicted = model(data)\n",
    "\n",
    "            loss = criterion(predicted, target)\n",
    "\n",
    "            epoch_loss += loss.item() * data.size(0)\n",
    "\n",
    "        _, pred_labels = torch.max(predicted.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += (pred_labels == target).sum().item()\n",
    "\n",
    "\n",
    "    return epoch_loss/dataset_size, correct/total\n",
    "\n",
    "\n",
    "def train_num_epochs(model, trainloader, testloader, device, criterion, optimizer, starting_epoch, ending_epoch, basic_name, path_to_weights):\n",
    "    '''\n",
    "    model - neural network\n",
    "    trainloader - pytorch dataloader for training set\n",
    "    testloader - pytorch dataloader for test set\n",
    "    device - cpu / cuda\n",
    "    criterion - loss function (nn.CrossEntropyLoss())\n",
    "    optimizer - (Adam)\n",
    "    starting_epoch - \n",
    "    ending_epoch - \n",
    "    '''\n",
    "    dataset_size = len(trainloader.dataset)  \n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    # iterate over epochs\n",
    "    for epoch_num in range(starting_epoch, ending_epoch):\n",
    "        print('Epoch #%d' % (epoch_num))\n",
    "\n",
    "        # iterate over batches\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        t0 = time.time()\n",
    "        for i, (data, target) in enumerate(trainloader):\n",
    "            \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # zero all the gradient tensors\n",
    "            optimizer.zero_grad()\n",
    "            # run forward step\n",
    "            predicted = model(data)\n",
    "\n",
    "            # compute loss\n",
    "            loss = criterion(predicted, target)\n",
    "\n",
    "            # compute gradient tensors\n",
    "            loss.backward()\n",
    "\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # compute the loss value\n",
    "            epoch_loss += loss.item() * data.size(0)\n",
    "            \n",
    "            total += target.size(0)\n",
    "            _, pred_labels = torch.max(predicted.data, 1)\n",
    "\n",
    "            correct += (pred_labels == target).sum().item()\n",
    "        \n",
    "        t = time.time() - t0\n",
    "            \n",
    "        \n",
    "        epoch_loss /=  dataset_size\n",
    "        train_acc = correct/total\n",
    "        print('# Time passed: %.0f s' % (t))\n",
    "        print('# Epoch loss = %.4f' % (epoch_loss))\n",
    "        print('# Train acc = {}'.format(train_acc))\n",
    "        print('# Validation process on validation set')\n",
    "        val_loss, val_acc = validate(model, criterion, testloader, device)\n",
    "        print('# Validation loss = {}'.format(val_loss))\n",
    "        print('# Validation acc = {}'.format(val_acc))\n",
    "\n",
    "        #print(val_acc > best_acc)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            model_name = basic_name + '_ep-{}_loss-{:.3}_acc-{:.3}.pth'.format(epoch_num, val_loss, val_acc)\n",
    "            path_to_saving_model = os.path.join(path_to_weights, model_name)\n",
    "            torch.save(mfcc_emotion_cnn.state_dict(), path_to_saving_model)\n",
    "            print('model %s have been saved' % (path_to_saving_model))\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        val_acc_list.append(val_acc)\n",
    "        train_loss_list.append(epoch_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "            \n",
    "    return model, train_acc_list, val_acc_list, train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7442\n"
     ]
    }
   ],
   "source": [
    "path_to_csv = os.path.join('/media/mikhail/files/datasets/emotion_recognition/CREMA-D', 'VideoDemographics.csv')\n",
    "demographic_info = pd.read_csv(path_to_csv)\n",
    "gender_df = demographic_info[['ActorID','Sex']]\n",
    "\n",
    "batch_size=256\n",
    "\n",
    "\n",
    "# CREMA-D\n",
    "target_path = '/media/mikhail/files/datasets/emotion_recognition/CREMA-D/AudioWAV'\n",
    "# IEMOCAP\n",
    "#target_path = '/media/mikhail/files/datasets/emotion_recognition/IEMOCAP/IEMOCAP_full_release/audios'\n",
    " \n",
    "npys_list = get_paths_to_wavs(target_path)\n",
    "\n",
    "# shuffle the dataset to for the learning process stability\n",
    "random.seed(0)\n",
    "random.shuffle(npys_list)\n",
    "\n",
    "dataset_size = len(npys_list)\n",
    "\n",
    "train_size = int(0.8 * dataset_size)\n",
    "\n",
    "print(dataset_size)\n",
    "\n",
    "train_dataset = crema_gender_dataset(npys_list[:train_size], (256, 256), 'TRAIN', gender_df)\n",
    "#train_dataset = numpy_iemocap_dataset(npys_list[:train_size], (256, 256), mode='TRAIN')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# set up test dataset and test dataloader\n",
    "test_dataset = crema_gender_dataset(npys_list[train_size:], (256, 256), 'TEST', gender_df)\n",
    "#test_dataset = numpy_iemocap_dataset(npys_list[train_size:], (256, 256), mode='TEST')\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Dropout(p=0.5, inplace=False)\n",
       "    (9): Linear(in_features=256, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [256, 64, 74, 74]           7,808\n",
      "              ReLU-2          [256, 64, 74, 74]               0\n",
      "         MaxPool2d-3          [256, 64, 36, 36]               0\n",
      "            Conv2d-4         [256, 192, 36, 36]         307,392\n",
      "              ReLU-5         [256, 192, 36, 36]               0\n",
      "         MaxPool2d-6         [256, 192, 17, 17]               0\n",
      "            Conv2d-7         [256, 384, 17, 17]         663,936\n",
      "              ReLU-8         [256, 384, 17, 17]               0\n",
      "            Conv2d-9         [256, 256, 17, 17]         884,992\n",
      "             ReLU-10         [256, 256, 17, 17]               0\n",
      "           Conv2d-11         [256, 256, 17, 17]         590,080\n",
      "             ReLU-12         [256, 256, 17, 17]               0\n",
      "        MaxPool2d-13           [256, 256, 8, 8]               0\n",
      "AdaptiveAvgPool2d-14           [256, 256, 6, 6]               0\n",
      "          Dropout-15                [256, 9216]               0\n",
      "           Linear-16                [256, 4096]      37,752,832\n",
      "             ReLU-17                [256, 4096]               0\n",
      "          Dropout-18                [256, 4096]               0\n",
      "           Linear-19                [256, 1024]       4,195,328\n",
      "             ReLU-20                [256, 1024]               0\n",
      "           Linear-21                 [256, 256]         262,400\n",
      "             ReLU-22                 [256, 256]               0\n",
      "          Dropout-23                 [256, 256]               0\n",
      "           Linear-24                  [256, 12]           3,084\n",
      "================================================================\n",
      "Total params: 44,667,852\n",
      "Trainable params: 44,667,852\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 87.31\n",
      "Forward/backward pass size (MB): 3720.40\n",
      "Params size (MB): 170.39\n",
      "Estimated Total Size (MB): 3978.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# set-up devices\n",
    "cuda = torch.device('cuda:0')\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "#model = audio_cnn(rows=256, cols=256, num_classes=len(train_dataset.emotions_dict))\n",
    "model = models.alexnet()\n",
    "model.features[0] = nn.Conv2d(1,  64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
    "model.classifier[4] = nn.Linear(4096, 1024)\n",
    "model.classifier[6] = nn.Linear(1024, 256)\n",
    "model.classifier.add_module('7', nn.ReLU(inplace=True))\n",
    "model.classifier.add_module('8', nn.Dropout())\n",
    "model.classifier.add_module('9', nn.Linear(256, len(train_dataset.emotions_dict)))\n",
    "\n",
    "'''\n",
    "model = models.vgg16_bn()\n",
    "model.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=4096, out_features=512, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5, inplace=False),\n",
    "    nn.Linear(in_features=512, out_features=len(train_dataset.emotions_dict), bias=True)\n",
    ")\n",
    "\n",
    "\n",
    "model = models.resnet34()\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Dropout(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, len(train_dataset.emotions_dict))\n",
    ")\n",
    "\n",
    "\n",
    "model = models.resnext50_32x4d()\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(2048, 512),\n",
    "    nn.Dropout(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Dropout(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, len(train_dataset.emotions_dict))\n",
    ")\n",
    "\n",
    "\n",
    "model = models.mobilenet_v2()\n",
    "model.features[0][0] = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(1280, 512),\n",
    "    nn.Dropout(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.Dropout(),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, len(train_dataset.emotions_dict))\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "model(torch.randn((1, 1, 256, 256)))\n",
    "\n",
    "summary(model, input_size=(1, 299, 299), batch_size=batch_size, device='cpu')\n",
    "\n",
    "device = cuda\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# define an optimization algorithm and bind it with the NN parameters\n",
    "optimizer = torch.optim.Adam(params=model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "\n",
    "starting_epoch = 0\n",
    "ending_epoch = 1000\n",
    "epoch_step = 1\n",
    "\n",
    "basic_name = '{}_log_pow_spec_norm_alexnet_lr_decay'.format('CREMA')\n",
    "\n",
    "\n",
    "\n",
    "path_to_weights = basic_name\n",
    "path_to_pkl = basic_name\n",
    "\n",
    "if not os.path.isdir(path_to_weights):\n",
    "    os.mkdir(path_to_weights)\n",
    "if not os.path.isdir(path_to_pkl):\n",
    "    os.mkdir(path_to_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " validation on 454 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #455\n",
      "Epoch time = 41.285 s\n",
      "Loss = 1.063009\tTraining acc = 0.609777\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 455 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #456\n",
      "Epoch time = 42.407 s\n",
      "Loss = 1.054113\tTraining acc = 0.614312\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 456 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #457\n",
      "Epoch time = 42.903 s\n",
      "Loss = 1.064859\tTraining acc = 0.609609\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 457 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #458\n",
      "Epoch time = 41.369 s\n",
      "Loss = 1.055401\tTraining acc = 0.615320\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 458 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #459\n",
      "Epoch time = 41.018 s\n",
      "Loss = 1.036991\tTraining acc = 0.618680\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 459 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #460\n",
      "Epoch time = 40.916 s\n",
      "Loss = 1.070602\tTraining acc = 0.608097\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 460 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #461\n",
      "Epoch time = 41.302 s\n",
      "Loss = 1.069521\tTraining acc = 0.610952\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 461 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #462\n",
      "Epoch time = 40.316 s\n",
      "Loss = 1.059993\tTraining acc = 0.610784\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 462 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #463\n",
      "Epoch time = 42.632 s\n",
      "Loss = 1.067475\tTraining acc = 0.607761\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 463 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #464\n",
      "Epoch time = 40.497 s\n",
      "Loss = 1.044840\tTraining acc = 0.616160\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 464 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #465\n",
      "Epoch time = 41.059 s\n",
      "Loss = 1.055689\tTraining acc = 0.604569\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 465 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #466\n",
      "Epoch time = 41.974 s\n",
      "Loss = 1.065657\tTraining acc = 0.606753\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 466 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #467\n",
      "Epoch time = 42.068 s\n",
      "Loss = 1.066243\tTraining acc = 0.613304\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 467 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #468\n",
      "Epoch time = 41.527 s\n",
      "Loss = 1.047892\tTraining acc = 0.620024\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 468 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #469\n",
      "Epoch time = 42.361 s\n",
      "Loss = 1.062829\tTraining acc = 0.610616\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 469 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #470\n",
      "Epoch time = 40.886 s\n",
      "Loss = 1.066646\tTraining acc = 0.605409\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 470 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #471\n",
      "Epoch time = 41.252 s\n",
      "Loss = 1.055746\tTraining acc = 0.604737\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 471 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #472\n",
      "Epoch time = 41.031 s\n",
      "Loss = 1.057795\tTraining acc = 0.606585\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 472 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #473\n",
      "Epoch time = 41.431 s\n",
      "Loss = 1.061289\tTraining acc = 0.616664\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 473 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #474\n",
      "Epoch time = 44.137 s\n",
      "Loss = 1.052210\tTraining acc = 0.609777\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 474 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #475\n",
      "Epoch time = 44.212 s\n",
      "Loss = 1.069837\tTraining acc = 0.604569\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 475 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #476\n",
      "Epoch time = 44.208 s\n",
      "Loss = 1.070270\tTraining acc = 0.608265\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 476 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #477\n",
      "Epoch time = 41.881 s\n",
      "Loss = 1.057752\tTraining acc = 0.615488\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 477 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #478\n",
      "Epoch time = 41.230 s\n",
      "Loss = 1.058632\tTraining acc = 0.616664\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 478 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #479\n",
      "Epoch time = 40.985 s\n",
      "Loss = 1.059863\tTraining acc = 0.615656\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 479 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #480\n",
      "Epoch time = 42.144 s\n",
      "Loss = 1.045297\tTraining acc = 0.612632\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 480 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #481\n",
      "Epoch time = 41.430 s\n",
      "Loss = 1.066351\tTraining acc = 0.610113\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 481 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #482\n",
      "Epoch time = 41.274 s\n",
      "Loss = 1.064444\tTraining acc = 0.606417\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 482 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #483\n",
      "Epoch time = 41.408 s\n",
      "Loss = 1.060309\tTraining acc = 0.614312\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 483 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #484\n",
      "Epoch time = 40.783 s\n",
      "Loss = 1.055412\tTraining acc = 0.609273\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 484 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #485\n",
      "Epoch time = 40.761 s\n",
      "Loss = 1.064333\tTraining acc = 0.606921\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 485 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #486\n",
      "Epoch time = 41.941 s\n",
      "Loss = 1.060537\tTraining acc = 0.610281\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 486 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #487\n",
      "Epoch time = 41.583 s\n",
      "Loss = 1.062469\tTraining acc = 0.614312\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 487 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #488\n",
      "Epoch time = 41.720 s\n",
      "Loss = 1.064251\tTraining acc = 0.607593\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 488 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #489\n",
      "Epoch time = 42.902 s\n",
      "Loss = 1.064975\tTraining acc = 0.607257\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 489 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #490\n",
      "Epoch time = 42.087 s\n",
      "Loss = 1.050139\tTraining acc = 0.607425\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 490 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #491\n",
      "Epoch time = 41.868 s\n",
      "Loss = 1.077853\tTraining acc = 0.601881\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 491 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #492\n",
      "Epoch time = 41.249 s\n",
      "Loss = 1.054810\tTraining acc = 0.612464\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 492 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #493\n",
      "Epoch time = 41.233 s\n",
      "Loss = 1.073228\tTraining acc = 0.608097\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 493 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #494\n",
      "Epoch time = 40.592 s\n",
      "Loss = 1.063795\tTraining acc = 0.606921\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 494 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #495\n",
      "Epoch time = 40.951 s\n",
      "Loss = 1.058187\tTraining acc = 0.615992\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 495 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #496\n",
      "Epoch time = 41.370 s\n",
      "Loss = 1.072264\tTraining acc = 0.604905\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 496 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #497\n",
      "Epoch time = 41.735 s\n",
      "Loss = 1.061025\tTraining acc = 0.612800\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 497 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #498\n",
      "Epoch time = 40.978 s\n",
      "Loss = 1.057393\tTraining acc = 0.611792\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 498 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n",
      "#############################################\n",
      "#\tStart training process\n",
      "#############################################\n",
      "\n",
      "\n",
      "Epoch #499\n",
      "Epoch time = 40.452 s\n",
      "Loss = 1.052823\tTraining acc = 0.609945\n",
      "----------------------------------------\n",
      "#############################################\n",
      "#\tStart validation on 499 epoch\n",
      "#############################################\n",
      "\tLoss = 1.2513\tValidation acc = 0.555\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "epochs = 500\n",
    "epoch_step = 1\n",
    "\n",
    "print('Start learning')\n",
    "\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "train_dataset_size = len(train_dataloader.dataset)  \n",
    "test_dataset_size = len(test_dataloader.dataset)  \n",
    "\n",
    "\n",
    "if os.path.exists(os.path.join(path_to_pkl, basic_name + '_train_loss.pkl')):\n",
    "    # Update existing classifier\n",
    "    with open(os.path.join(path_to_pkl, basic_name + '_train_loss.pkl'), \"rb\") as f:\n",
    "        train_loss_list = pickle.load(f)\n",
    "else:\n",
    "  train_loss_list = []\n",
    "\n",
    "if os.path.exists(os.path.join(path_to_pkl, basic_name + '_train_acc.pkl')):\n",
    "    # Update existing classifier\n",
    "    with open(os.path.join(path_to_pkl, basic_name + '_train_acc.pkl'), \"rb\") as f:\n",
    "        train_acc_list = pickle.load(f)\n",
    "else:\n",
    "  train_acc_list = []\n",
    "\n",
    "if os.path.exists(os.path.join(path_to_pkl, basic_name + '_val_loss.pkl')):\n",
    "    # Update existing classifier\n",
    "    with open(os.path.join(path_to_pkl, basic_name + '_val_loss.pkl'), \"rb\") as f:\n",
    "        val_loss_list = pickle.load(f)\n",
    "else:\n",
    "  val_loss_list = []\n",
    "\n",
    "if os.path.exists(os.path.join(path_to_pkl, basic_name + '_val_acc.pkl')):\n",
    "    # Update existing classifier\n",
    "    with open(os.path.join(path_to_pkl, basic_name + '_val_acc.pkl'), \"rb\") as f:\n",
    "        val_acc_list = pickle.load(f)\n",
    "else:\n",
    "    val_acc_list = []\n",
    "\n",
    "\n",
    "t = 0.0\n",
    "\n",
    "for epoch_idx in range(start_epoch, epochs, epoch_step):\n",
    "\n",
    "    print('#############################################')\n",
    "    print('#\\tStart training process')\n",
    "    print('#############################################\\n\\n')\n",
    "\n",
    "    # iterate over epochs\n",
    "    for epoch in range(epoch_step):\n",
    "        print('Epoch #{}'.format(epoch_idx + epoch))\n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "        # define losses and correct valuse number for each epoch\n",
    "        epoch_train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # iterate over batches\n",
    "        for data, labels in train_dataloader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item() * data.size(0)\n",
    "            total += labels.size(0)\n",
    "            _, pred_labels = torch.max(pred.data, 1)\n",
    "\n",
    "            correct += (pred_labels == labels).sum().item()\n",
    "\n",
    "        t1 = time.time()\n",
    "\n",
    "        print('Epoch time = {:.3f} s'.format(t1 - t0))\n",
    "\n",
    "        train_loss = epoch_train_loss / train_dataset_size\n",
    "        train_acc = correct/total\n",
    "\n",
    "        train_acc_list.append(train_acc)\n",
    "        train_loss_list.append(train_loss)\n",
    "\n",
    "        print('Loss = %f\\tTraining acc = %f' % (train_loss, train_acc))\n",
    "        print('----------------------------------------')\n",
    "        \n",
    "        print('#############################################')\n",
    "        print('#\\tStart validation on %d epoch' % (epoch_idx + epoch))\n",
    "        print('#############################################')\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            true_values = 0.0\n",
    "            epoch_test_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data, labels in test_dataloader:\n",
    "                data = data.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # run the model\n",
    "                pred = model(data)\n",
    "                loss = criterion(pred, labels)\n",
    "                epoch_test_loss += loss.item() * data.size(0)\n",
    "                total += labels.size(0)\n",
    "                _, pred_labels = torch.max(pred.data, 1)\n",
    "                correct += (pred_labels == labels).sum().item()\n",
    "        val_acc = correct/total\n",
    "        val_loss = epoch_test_loss / test_dataset_size\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)\n",
    "                \n",
    "        print('\\tLoss = {:.4f}\\tValidation acc = {:.3f}'.format(val_loss, val_acc))\n",
    "        print('---------------------------------------------')\n",
    "\n",
    "        scheduler.step()\n",
    "      \n",
    "        # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "        #save current model to resume training\n",
    "        #после каждой эпохи сохраняем веса для того, чтобы потом продолжить обучение именно с последней эпохи\n",
    "        #а не с эпохи с лучшими весами \n",
    "        path_to_saving_model = os.path.join(path_to_weights, basic_name + '_current.pth')\n",
    "        torch.save(model.state_dict(), path_to_saving_model)\n",
    "            \n",
    "        if val_acc > best_acc:\n",
    "            print('#############################################')\n",
    "            print('#\\tBest accuracy has achieved')\n",
    "            print('#\\tSaving weights...')\n",
    "            print('#############################################\\n\\n')\n",
    "\n",
    "            model_name = basic_name + '_ep-{}_loss-{:.3}_acc-{:.3}.pth'.format(epoch_idx + epoch, val_loss, val_acc)\n",
    "            path_to_saving_model = os.path.join(path_to_weights, model_name)\n",
    "\n",
    "            torch.save(model.state_dict(), path_to_saving_model)\n",
    "            print('model {} have been saved'.format(path_to_saving_model))\n",
    "            best_acc = val_acc\n",
    "\n",
    "        with open(os.path.join(path_to_pkl, basic_name + '_train_loss.pkl'), 'wb') as f:\n",
    "            pickle.dump(train_loss_list, f)\n",
    "\n",
    "        with open(os.path.join(path_to_pkl, basic_name + '_train_acc.pkl'), 'wb') as f:\n",
    "            pickle.dump(train_acc_list, f)\n",
    "\n",
    "        with open(os.path.join(path_to_pkl, basic_name + '_val_loss.pkl'), 'wb') as f:\n",
    "            pickle.dump(val_loss_list, f)\n",
    "\n",
    "        with open(os.path.join(path_to_pkl, basic_name + '_val_acc.pkl'), 'wb') as f:\n",
    "            pickle.dump(val_acc_list, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOm4PdkilN9IYsfOR5k7M6d",
   "collapsed_sections": [],
   "name": "test_audio.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
